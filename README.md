# pdf-chatbot-ai (PDF Question Answering App)
An AI chatbot that reads PDFs and answers questions using a BERT model.

A **Streamlit-based AI Q&A app** that reads multiple PDF documents, extracts their text, and allows users to **ask natural language questions**.  
The app uses a **pretrained BERT model** (`bert-large-uncased-whole-word-masking-finetuned-squad`) from Hugging Faceâ€™s `transformers` library to find accurate answers from your PDFs.

---

## ğŸš€ Features

- ğŸ“˜ Load all PDFs from a folder (`docs/`)
- ğŸ§  Uses Hugging Face Transformers pipeline for Question Answering
- âš¡ Caches extracted text and model for faster reloads
- ğŸ¤– Smart handling of compound questions (e.g., â€œWhen and where was he born?â€)
- ğŸ¨ Simple and clean Streamlit UI

---

## ğŸ—‚ï¸ Project Structure

```
ğŸ“¦ PDF-QA-App
â”‚
â”œâ”€â”€ app.py                # Main Streamlit app
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ docs/                 # Folder containing PDF files
â””â”€â”€ README.md             # Project documentation
```

---

## ğŸ§© Requirements

Make sure you have **Python 3.9+** installed.

---

## âš™ï¸ Setup Instructions

### 1. Clone or copy the project
```bash
git clone <your-repo-url>
cd PDF-QA-App
```

### 2. Create and activate virtual environment
```bash
python -m venv .venv
.venv\Scripts\activate   # On Windows
# or
source .venv/bin/activate  # On Mac/Linux
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

Ensure your `requirements.txt` includes:
```
streamlit
transformers
torch
PyPDF2
```

### 4. Add your PDFs
Place all PDF files inside the `docs/` folder.

Example:
```
docs/
â”œâ”€â”€ biography_kalam.pdf
â”œâ”€â”€ barack_obama.pdf
```

### 5. Run the app
```bash
streamlit run app.py
```

Then open the provided local URL (e.g., http://localhost:8501) in your browser.

---

## ğŸ’¬ How It Works

1. Extracts text from all PDFs (cached for reuse)
2. Loads a Hugging Face question-answering pipeline
3. Splits text into manageable chunks for efficient searching
4. Uses BERT to find the most relevant answer
5. Supports compound questions like â€œWhen and where was Dr. Kalam born?â€

---

## ğŸ§  Model Used
**BERT Large Uncased Whole Word Masking (SQuAD fine-tuned)**  
> Model: `bert-large-uncased-whole-word-masking-finetuned-squad`

---

## ğŸ› ï¸ Troubleshooting

- âŒ `ImportError: cannot import name 'pipeline'`
  â†’ Run: `pip install -U transformers`

- âŒ `ModuleNotFoundError: No module named 'torch'`
  â†’ Run: `pip install torch`

- ğŸ•’ Long first run?
  â†’ The model downloads (~1.3 GB) only once; subsequent runs are cached.

---

## ğŸ“„ License

This project is open source under the **MIT License**.

---

## âœ¨ Example Use Case

> Upload biographies of leaders, company manuals, or research papers,  
> then ask:  
> â€œWhat was his major contribution?â€ or â€œWhen and where was he born?â€  
> and get instant answers â€” powered by BERT.
